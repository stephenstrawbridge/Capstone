{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/film_logo.jpeg' style='float:left; width:200px;height:200px'/>\n",
    "\n",
    "#  <h1><center> Capstone Project: Film Linguistics </center></h1>\n",
    "#  Notebook 1 - Introduction and Data Cleaning\n",
    "####  Stephen Strawbridge, Cohort #1019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hypothesize that movie production companies are not as accurate as they could be in anticipating their reviews from viewers, due to the lack of consideration in linguistic features used in script. This project aims to create the most ideal prediction model(s), with an emphasis on script linguistics, so that production companies can anticipate their review success during the production phase and adjust budgets accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Cleaning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephenstrawbridge/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (10,12,14,16,18,20,22,24,26,28,30,32,34,44,46,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143,145,147,149,151,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,211,213,215,217,219,221,223) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Read in dataset\n",
    "df = pd.read_csv('./CSVs/original_df.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30493 entries, 0 to 30492\n",
      "Columns: 224 entries, MovieID to Filler-ratio\n",
      "dtypes: float64(6), int64(120), object(98)\n",
      "memory usage: 52.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Look at overall info on dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_number                 58\n",
       "plot_summary               28887\n",
       "made_for                   27198\n",
       "suspended                  30479\n",
       "running_time                1877\n",
       "running_time_comment       27406\n",
       "country                        7\n",
       "USAonly_1_other_0              7\n",
       "rating_dist                  568\n",
       "rating_votes                 568\n",
       "rating_rank                  568\n",
       "CERT_dummycode             16972\n",
       "cert-west-germany          26482\n",
       "genre1                       257\n",
       "genre2                      9686\n",
       "genre3                     19502\n",
       "PrimaryGenre_dummycoded      257\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Isolate for columns with null values\n",
    "nan_cols = [i for i in df if df[i].isnull().any()]\n",
    "df[nan_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneeded rows and columns\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, drop unecessary columns for project\n",
    "df = df.drop(columns=['random_number', 'CERT_dummycode', 'cert-west-germany', 'SubActualCD', 'suspended',\n",
    "                      'SubSumCD', 'plot_summary', 'made_for', 'SubDownloadsCnt.1', 'TotalWords.1', 'rating_dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map the phrase 'Not provided' to object columns with null values\n",
    "obj_null_cols = ['running_time', 'running_time_comment', 'country']\n",
    "\n",
    "for col in obj_null_cols:\n",
    "    df[col] = df[col].replace(np.nan, 'Not provided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because ratings will be a primary target variable in project, rows where rating data is missing will be dropped\n",
    "df = df[df['rating_votes'].notna()]\n",
    "df = df[df['rating_rank'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For genres, our dataframe already has the genres dummified, so we can drop the original genre columns\n",
    "df = df.drop(columns=['genre1', 'genre2', 'genre3', 'PrimaryGenre_dummycoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the 6 null rows in the USAonly column\n",
    "df = df[df['USAonly_1_other_0'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check that no more nulls exist in dataframe\n",
    "nan_cols = [i for i in df if df[i].isnull().any()]\n",
    "df[nan_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Because we are specifically looking at the linguistic characteristic ratios, we will create column list of all ratio features.  The total initial number of ratios is 86.\n",
    "---\n",
    "After running models in the subsequent notebooks, it was noted that many of the ratios had little to no predictive value, and if anything, were a detriment to the modeling process.  For this reason, many of the ratios will be dropped.  Ratios were dropped according to either a low value count and/or low correlation with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ratios deemed invaluable to models in subsequent notebooks\n",
    "ratios_to_drop = ['Pronoun-ratio', 'Ppron-ratio', 'I-ratio', 'We-ratio', 'You-ratio', 'SheHe-ratio', 'They-ratio',\n",
    "                 'Ipron-ratio', 'Article-ratio', 'Prep-ratio', 'Auxverb-ratio', 'Adverb-ratio', 'Conj-ratio',\n",
    "                 'Compare-ratio', 'Number-ratio', 'Quant-ratio', 'Affect-ratio', 'Posemo-ratio', 'Negemo-ratio',\n",
    "                 'Anx-ratio', 'CogProc-ratio', 'Insight-ratio', 'Cause-ratio', 'Discrep-ratio', 'Tentat-ratio',\n",
    "                 'Certain-ratio', 'Differ-ratio', 'Percept-ratio', 'See-ratio', 'Hear-ratio', 'Feel-ratio', 'Bio-ratio',\n",
    "                 'Body-ratio', 'Health-ratio', 'Ingest-ratio', 'Drives-ratio', 'Affiliation-ratio', 'Achieve-ratio',\n",
    "                 'Power-ratio', 'Relativ-ratio', 'Motion-ratio', 'Space-ratio', 'Time-ratio', 'Work-ratio', 'Leisure-ratio',\n",
    "                 'Home-ratio', 'Netspeak-ratio', 'Assent-ratio', 'Nonflu-ratio']\n",
    "\n",
    "#Drop associated word count columns with these ratios, as we are only concerned with word ratios, not word counts\n",
    "wordcounts_to_drop = ['Pronoun', 'Ppron', 'I', 'We', 'You', 'SheHe', 'They', 'Ipron', 'Article', 'Prep', 'Auxverb',\n",
    "                      'Adverb', 'Conj', 'Compare', 'Number', 'Quant', 'Affect', 'Posemo', 'Negemo', 'Anx', 'CogProc',\n",
    "                      'Insight', 'Cause', 'Discrep', 'Tentat', 'Certain', 'Differ', 'Percept', 'See', 'Hear', 'Feel',\n",
    "                      'Bio', 'Body', 'Health', 'Ingest', 'Drives', 'Affiliation', 'Achieve', 'Power', 'Relativ',\n",
    "                      'Motion', 'Space', 'Time', 'Work', 'Leisure', 'Home', 'Netspeak', 'Assent', 'Nonflu']\n",
    "\n",
    "#Drop ratio's that dominated the frequency of occurence, as these ratios would become to influencing on the model\n",
    "other_to_drop = ['Function', 'Function-ratio', 'Verb', 'Verb-ratio']\n",
    "\n",
    "#Remove ratio cols, and their respective word count cols, and other ratios, from final ratios list\n",
    "df = df.drop(columns=ratios_to_drop)\n",
    "df = df.drop(columns=wordcounts_to_drop)\n",
    "df = df.drop(columns=other_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only keep dataframe for which there is at least 1000 votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['rating_votes'] > 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ratio_cols list of all ratio features that we want to keep (e.g. was not dropped in previous cell)\n",
    "ratio_cols = [col for col in df.columns if 'ratio' in col]\n",
    "\n",
    "#It was noticed that a question mark was present in ratio columns\n",
    "#The rows with this question mark were dropped\n",
    "for col in df[ratio_cols]:\n",
    "    df = df[df[col] != '?']\n",
    "    \n",
    "#Convert columns to floats (they are currently object types)\n",
    "df[ratio_cols] = df[ratio_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check out final number of ratios used\n",
    "len(ratio_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HarmVirtue-ratio',\n",
       " 'HarmVice-ratio',\n",
       " 'FairnessVirtue-ratio',\n",
       " 'FairnessVice-ratio',\n",
       " 'IngroupVirtue-ratio',\n",
       " 'IngroupVice-ratio',\n",
       " 'AuthorityVirtue-ratio',\n",
       " 'AuthorityVice-ratio',\n",
       " 'PurityVirtue-ratio',\n",
       " 'PurityVice-ratio',\n",
       " 'MoralityGeneral-ratio',\n",
       " 'Negative-ratio',\n",
       " 'Positive-ratio',\n",
       " 'Negate-ratio',\n",
       " 'Adj-ratio',\n",
       " 'Interrog-ratio',\n",
       " 'Anger-ratio',\n",
       " 'Sad-ratio',\n",
       " 'Social-ratio',\n",
       " 'Family-ratio',\n",
       " 'Friend-ratio',\n",
       " 'Female-ratio',\n",
       " 'Male-ratio',\n",
       " 'Sexual-ratio',\n",
       " 'Reward-ratio',\n",
       " 'Risk-ratio',\n",
       " 'FocusPast-ratio',\n",
       " 'FocusPresent-ratio',\n",
       " 'FocusFuture-ratio',\n",
       " 'Money-ratio',\n",
       " 'Relig-ratio',\n",
       " 'Death-ratio',\n",
       " 'Informal-ratio',\n",
       " 'Swear-ratio',\n",
       " 'Filler-ratio']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at final ratio list\n",
    "ratio_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Brief feature engineering/renaming/modifications\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column called 'years_old' to indicate how old a certain movie is\n",
    "df['years_old'] = 2021 - df['MovieYear']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Clean country columns (note these columns were already dummified)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change country columns to integer types (currently stored as floats)\n",
    "df['USAonly_1_other_0'] = df['USAonly_1_other_0'].astype(int)\n",
    "df['USAany_1_other_0'] = df['USAany_1_other_0'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It was noticed that a question mark was present in ratio columns\n",
    "#The rows with this question mark were dropped\n",
    "for col in df.columns:\n",
    "    df = df[df[col] != '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Drop rows for which word count is below 1,000 words\n",
    "---\n",
    "Because this model seeks to predict based off of word count ratios, ratios could become distorted if word counts are significantly low.  Also, integrity of the dataset is maintained as only a small percentage of movies have word counts below 1,000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with word counts below 1,000\n",
    "df = df[df['TotalWords'] > 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Drop rows for movies older than 30 years old\n",
    "---\n",
    "Because this model seeks to predict rating based off of English vernacular, vernacular from over 30 years ago could be significantly different than the vernacular seen and produced today.  Additionally, integrity of the dataset is maintained as the dataset still includes over 18,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with years_old greater than 30\n",
    "df = df[df['years_old'] < 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Double check before saving\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieName\n",
      "running_time\n",
      "running_time_comment\n",
      "country\n"
     ]
    }
   ],
   "source": [
    "#Double check datatypes of columns (only select few columns should be object type)\n",
    "for col in df:\n",
    "    if df[col].dtype == object:\n",
    "        print(col)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check that no more nulls exist in dataframe\n",
    "nan_cols = [i for i in df if df[i].isnull().any()]\n",
    "df[nan_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9970, 108)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Finally, save the fully cleaned CSV to be imported in subsequent notebooks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned dataframe to CSV\n",
    "df.to_csv('./CSVs/cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned dataframe to Excel for reference purposes\n",
    "#df.to_excel('./Excels/cleaned_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save cleaned dataframe to Excel for Tableau purposes\n",
    "#df.to_excel('./Excels/tableau_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
